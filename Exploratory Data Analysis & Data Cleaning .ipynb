{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6BR9Mkm4sEnXWuAvYfN/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TarekAzzouni/Boston-Consulting-Group-Virtual-Internship/blob/main/Exploratory%20Data%20Analysis%20%26%20Data%20Cleaning%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENMDf8dTKhxr"
      },
      "source": [
        "The BCG project team thinks that building a churn model to understand whether price sensitivity is the largest driver of churn has potential. The client has sent over some data and the LDS wants you to perform some exploratory data analysis and data cleaning.\n",
        "\n",
        "The data that was sent over includes:\n",
        "\n",
        "Historical customer data: Customer data such as usage, sign up date, forecasted usage etc\n",
        "Historical pricing data: variable and fixed pricing data etc\n",
        "Churn indicator: whether each customer has churned or not\n",
        "\n",
        "These datasets are otherwise identical and have historical price data and customer data (including churn status for the customers in the training data).\n",
        "\n",
        "Please submit your data as code script or a PDF version of the script/notebook. We recommend spending no more than 1.5 hours on this task.\n",
        "\n",
        "Objectives: \n",
        "\n",
        "\n",
        "*   Clean the data â€“ you might have to address missing values, duplicates, data type conversions, transformations, and multicolinearity, as well as outliers.\n",
        "*   Perform some exploratory data analysis. Look into the data types, data statistics, and identify any missing data or null values, and how often they appear in the data. Visualize specific parameters as well as variable distributions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc3Wruh6KdOt"
      },
      "source": [
        "Project management \n",
        "\n",
        "1) Libraries and Data Loading\n",
        "\n",
        "2) Exploratory Analysis and Data Cleaning\n",
        "\n",
        "3) Machine Learning\n",
        "\n",
        "4) Adjustment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIEdCSypJz-I"
      },
      "source": [
        "*Import libraries *\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J8ydv3fI4G2"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnqwowZ1KB4g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}